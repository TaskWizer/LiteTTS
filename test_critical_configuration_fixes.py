#!/usr/bin/env python3
"""
Comprehensive test script to validate critical configuration fixes
Tests all three configuration errors that were blocking dashboard audio generation
"""

import sys
import os
import time
from pathlib import Path

# Add the project root to Python path
sys.path.insert(0, str(Path(__file__).parent))

def test_monitoring_config_metrics_endpoint():
    """Test that MonitoringConfig has metrics_endpoint attribute"""
    print("üß™ Testing MonitoringConfig metrics_endpoint fix...")
    
    try:
        from LiteTTS.config import config
        
        # Test that monitoring config has all required attributes
        monitoring = config.monitoring
        
        # Test the previously missing attributes
        metrics_endpoint = monitoring.metrics_endpoint
        health_endpoint = monitoring.health_endpoint
        performance_endpoint = monitoring.performance_endpoint
        request_tracking = monitoring.request_tracking
        performance_logging = monitoring.performance_logging
        metrics_retention_days = monitoring.metrics_retention_days
        
        print(f"‚úÖ MonitoringConfig attributes accessible:")
        print(f"   metrics_endpoint: {metrics_endpoint}")
        print(f"   health_endpoint: {health_endpoint}")
        print(f"   performance_endpoint: {performance_endpoint}")
        print(f"   request_tracking: {request_tracking}")
        print(f"   performance_logging: {performance_logging}")
        print(f"   metrics_retention_days: {metrics_retention_days}")
        
        # Test the to_dict() method that was causing the original error
        config_dict = config.to_dict()
        monitoring_dict = config_dict.get('monitoring', {})
        
        if 'metrics_endpoint' in monitoring_dict:
            print("‚úÖ to_dict() method works correctly with metrics_endpoint")
        else:
            print("‚ùå to_dict() method missing metrics_endpoint")
            return False
        
        return True
        
    except AttributeError as e:
        print(f"‚ùå MonitoringConfig attribute error: {e}")
        return False
    except Exception as e:
        print(f"‚ùå MonitoringConfig test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_cpu_optimizer_aggressive_config():
    """Test that CPUOptimizer has get_aggressive_performance_config method"""
    print("\nüß™ Testing CPUOptimizer get_aggressive_performance_config fix...")
    
    try:
        from LiteTTS.performance.cpu_optimizer import CPUOptimizer
        
        optimizer = CPUOptimizer()
        
        # Test the previously missing method
        aggressive_config = optimizer.get_aggressive_performance_config()
        
        print(f"‚úÖ get_aggressive_performance_config() method works")
        print(f"   Config keys: {list(aggressive_config.keys())}")
        print(f"   ONNX threads: inter={aggressive_config.get('onnx_inter_op_threads', 'N/A')}, intra={aggressive_config.get('onnx_intra_op_threads', 'N/A')}")
        print(f"   Workers: {aggressive_config.get('workers', 'N/A')}")
        print(f"   Batch size: {aggressive_config.get('batch_size', 'N/A')}")
        
        # Verify it returns the same as get_recommended_settings(aggressive=True)
        recommended_config = optimizer.get_recommended_settings(aggressive=True)
        
        if aggressive_config == recommended_config:
            print("‚úÖ Method returns correct aggressive configuration")
        else:
            print("‚ö†Ô∏è Method returns different config than expected")
        
        return True
        
    except AttributeError as e:
        print(f"‚ùå CPUOptimizer method error: {e}")
        return False
    except Exception as e:
        print(f"‚ùå CPUOptimizer test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_simd_optimizer_platform_fix():
    """Test that SIMD optimizer platform variable scope is fixed"""
    print("\nüß™ Testing SIMD optimizer platform variable scope fix...")
    
    try:
        from LiteTTS.performance.simd_optimizer import SIMDOptimizer
        
        # This should not raise a platform variable scope error
        optimizer = SIMDOptimizer()
        
        # Test CPU flag detection (the method that had the scope issue)
        flags = optimizer._get_cpu_flags_fallback()
        
        print(f"‚úÖ SIMD optimizer initialized successfully")
        print(f"   Detected instruction set: {optimizer.capabilities.optimal_instruction_set}")
        print(f"   Vector width: {optimizer.capabilities.vector_width}")
        print(f"   CPU flags detected: {len(flags)} flags")
        
        # Test SIMD capabilities detection
        capabilities = optimizer._detect_simd_capabilities()
        
        print(f"‚úÖ SIMD capabilities detection works")
        print(f"   AVX2: {capabilities.avx2}")
        print(f"   AVX512: {capabilities.avx512f}")
        print(f"   SSE4.2: {capabilities.sse4_2}")
        
        return True
        
    except Exception as e:
        error_msg = str(e)
        if "cannot access local variable 'platform'" in error_msg:
            print(f"‚ùå Platform variable scope error still exists: {e}")
        else:
            print(f"‚ùå SIMD optimizer test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_integrated_optimizer_compatibility():
    """Test that integrated optimizer works with all fixes"""
    print("\nüß™ Testing integrated optimizer with all fixes...")
    
    try:
        from LiteTTS.performance.integrated_optimizer import IntegratedPerformanceOptimizer
        
        # This should work without any configuration errors
        optimizer = IntegratedPerformanceOptimizer()
        
        # Test CPU optimization (uses get_aggressive_performance_config)
        cpu_success = optimizer._optimize_cpu()
        print(f"‚úÖ CPU optimization: {'Success' if cpu_success else 'Failed'}")
        
        # Test system optimization (uses apply_memory_optimizations)
        system_success = optimizer._optimize_system()
        print(f"‚úÖ System optimization: Success")
        
        # Test memory optimization
        memory_success = optimizer._optimize_memory()
        print(f"‚úÖ Memory optimization: {'Success' if memory_success else 'Failed'}")
        
        # Get optimization status
        status = optimizer.get_optimization_status()
        print(f"‚úÖ Optimization status retrieved")
        print(f"   Applied: {status.get('optimization_applied', False)}")
        print(f"   Memory usage: {status.get('current_memory_mb', 0):.1f}MB")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Integrated optimizer test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_dashboard_tts_optimizer_end_to_end():
    """Test dashboard TTS optimizer end-to-end functionality"""
    print("\nüß™ Testing dashboard TTS optimizer end-to-end...")
    
    try:
        from LiteTTS.api.dashboard_tts_optimizer import DashboardTTSOptimizer
        from LiteTTS.models import TTSRequest
        
        # Initialize optimizer
        optimizer = DashboardTTSOptimizer()
        
        # Test TTSRequest creation (previous fix)
        request = TTSRequest(
            input="Test configuration fixes",
            voice="af_heart",
            response_format="mp3",
            speed=1.0,
            stream=True,
            volume_multiplier=1.0
        )
        
        print(f"‚úÖ TTSRequest creation works")
        
        # Test validation methods
        validation_error = optimizer._validate_dashboard_request("Test", "af_heart", "mp3")
        if validation_error is None:
            print("‚úÖ Request validation works")
        else:
            print(f"‚ö†Ô∏è Validation issue: {validation_error}")
        
        # Test error categorization
        error_category = optimizer._categorize_error(ValueError("Test error"))
        print(f"‚úÖ Error categorization works: {error_category}")
        
        # Test metrics collection
        metrics = optimizer.get_performance_summary()
        print(f"‚úÖ Performance metrics collection works")
        print(f"   Total requests: {metrics.get('total_requests', 0)}")
        print(f"   Optimization enabled: {metrics.get('optimization_enabled', False)}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Dashboard TTS optimizer test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Run all critical configuration tests"""
    print("üöÄ Testing Critical Configuration Fixes")
    print("=" * 70)
    
    results = []
    
    # Test 1: MonitoringConfig metrics_endpoint fix
    results.append(test_monitoring_config_metrics_endpoint())
    
    # Test 2: CPUOptimizer get_aggressive_performance_config fix
    results.append(test_cpu_optimizer_aggressive_config())
    
    # Test 3: SIMD optimizer platform variable scope fix
    results.append(test_simd_optimizer_platform_fix())
    
    # Test 4: Integrated optimizer compatibility
    results.append(test_integrated_optimizer_compatibility())
    
    # Test 5: Dashboard TTS optimizer end-to-end
    results.append(test_dashboard_tts_optimizer_end_to_end())
    
    # Summary
    print("\n" + "=" * 70)
    print("üìä CRITICAL CONFIGURATION FIXES SUMMARY")
    print("=" * 70)
    
    passed = sum(results)
    total = len(results)
    
    print(f"‚úÖ Tests passed: {passed}/{total}")
    
    if passed == total:
        print("üéâ ALL CRITICAL CONFIGURATION ERRORS RESOLVED!")
        print("\nüîß Key fixes implemented:")
        print("  ‚Ä¢ Fixed MonitoringConfig missing metrics_endpoint attribute")
        print("  ‚Ä¢ Added CPUOptimizer.get_aggressive_performance_config() method")
        print("  ‚Ä¢ Fixed SIMD optimizer platform variable scope error")
        print("  ‚Ä¢ Updated settings.json with complete monitoring configuration")
        print("  ‚Ä¢ Validated integrated optimizer compatibility")
        print("\n‚ú® Dashboard TTS system is now fully operational!")
        print("üöÄ HTTP 500 errors should be eliminated")
        print("‚ö° Performance optimizations are working correctly")
    else:
        print("‚ö†Ô∏è Some critical configuration tests failed - review the output above")
        print("‚ùå Dashboard TTS may still experience configuration errors")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
